<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Verrazzano Enterprise Container Platform â€“ Monitoring &amp; Logging</title>
    <link>/docs/monitoring/</link>
    <description>Recent content in Monitoring &amp; Logging on Verrazzano Enterprise Container Platform</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/docs/monitoring/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Logging</title>
      <link>/docs/monitoring/logs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/monitoring/logs/</guid>
      <description>
        
        
        &lt;p&gt;The Verrazzano logging stack consists of Fluentd, Elasticsearch, and Kibana components.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fluentd: a log aggregator that collects, processes, and formats logs from Kubernetes clusters.&lt;/li&gt;
&lt;li&gt;Elasticsearch: a scalable search and analytics engine for storing Kubernetes logs.&lt;/li&gt;
&lt;li&gt;Kibana: a visualization layer that provides a user interface to query and visualize collected logs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As shown in the following diagram, logs written to stdout by a container running on Kubernetes are picked up by the kubelet service running on that node and written to &lt;code&gt;/var/log/containers&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../docs/images/logging.png&#34; alt=&#34;Logging&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;fluentd-sidecar&#34;&gt;Fluentd sidecar&lt;/h2&gt;
&lt;p&gt;For components with multiple log streams or that cannot log to stdout, Verrazzano deploys a Fluentd sidecar which parses and translates the log stream.  The resulting log is sent to stdout of the sidecar container and then written to &lt;code&gt;/var/log/containers&lt;/code&gt; by the kubelet service.&lt;/p&gt;
&lt;p&gt;For example, in a WebLogic deployment, &lt;code&gt;AdminServer.log&lt;/code&gt; is consumed, translated, and written to stdout by the Fluentd sidecar.  You can view these logs using &lt;code&gt;kubectl&lt;/code&gt; on the container named &lt;code&gt;fluentd-stdout-sidecar&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl logs tododomain-adminserver \
   -n todo-list \
   -c fluentd-stdout-sidecar
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The Verrazzano Fluentd Docker image comes with these plug-ins:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/fluent-plugins-nursery/fluent-plugin-concat&#34;&gt;fluent-plugin-concat&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/lunardial/fluent-plugin-dedot_filter&#34;&gt;fluent-plugin-dedot_filter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/fluent-plugin-detect-exceptions&#34;&gt;fluent-plugin-detect-exceptions &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.fluentd.org/output/elasticsearch&#34;&gt;fluent-plugin-elasticsearch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/fluent/fluent-plugin-grok-parser&#34;&gt;fluent-plugin-grok-parser&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rubygems.org/gems/fluent-plugin-json-in-json-2&#34;&gt;fluent-plugin-json-in-json-2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter&#34;&gt;fluent-plugin-kubernetes_metadata_filter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/repeatedly/fluent-plugin-multi-format-parser&#34;&gt;fluent-plugin-multi-format-parser&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/fluent/fluent-plugin-parser-cri&#34;&gt;fluent-plugin-parser-cri&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/fluent/fluent-plugin-prometheus&#34;&gt;fluent-plugin-prometheus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/repeatedly/fluent-plugin-record-modifier&#34;&gt;fluent-plugin-record-modifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/fluent/fluent-plugin-rewrite-tag-filter&#34;&gt;fluent-plugin-rewrite-tag-filter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/fluent-plugin-systemd/fluent-plugin-systemd&#34;&gt;fluent-plugin-systemd&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Verrazzano Fluentd Docker image also has two local default plug-ins, &lt;code&gt;kubernetes_parser&lt;/code&gt; and &lt;code&gt;kubernetes_multiline_parser&lt;/code&gt;.
These plug-ins help to parse Kubernetes management log files.&lt;/p&gt;
&lt;p&gt;Here are example use cases for these plug-ins:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ---- fluentd.conf ----
# kubernetes parser
&amp;lt;source&amp;gt;
  @type tail
  path ./kubelet.log
  read_from_head yes
  tag kubelet
  &amp;lt;parse&amp;gt;
     @type multiline_kubernetes
  &amp;lt;/parse&amp;gt;
&amp;lt;/source&amp;gt;

# kubernetes multi-line parser
&amp;lt;source&amp;gt;
  @type tail
  path ./kubelet.log
  read_from_head yes
  tag kubelet
  &amp;lt;parse&amp;gt;
     @type multiline_kubernetes
  &amp;lt;/parse&amp;gt;
&amp;lt;/source&amp;gt;
# ----   EOF      ----
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For more details, see the &lt;a href=&#34;https://github.com/verrazzano/fluentd-kubernetes-daemonset/tree/oracle-build-from-source-v1.12/docker-image/v1.12/oraclelinux-elasticsearch7/plugins&#34;&gt;Fluentd plugins&lt;/a&gt; folder.&lt;/p&gt;
&lt;h2 id=&#34;fluentd-daemonset&#34;&gt;Fluentd DaemonSet&lt;/h2&gt;
&lt;p&gt;Verrazzano deploys a Fluentd DaemonSet which runs one Fluentd replica per node in the &lt;code&gt;verrazzano-system&lt;/code&gt; namespace.
Each instance pulls logs from the node&amp;rsquo;s &lt;code&gt;/var/log/containers&lt;/code&gt; directory and writes them to the target Elasticsearch index.  The index name is based on the namespace associated with the record, using this format: &lt;code&gt;verrazzano-namespace-&amp;lt;record namespace&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example, &lt;code&gt;vmi-system-kibana&lt;/code&gt; logs written to &lt;code&gt;/var/log/containers&lt;/code&gt; will be pulled by Fluentd and written to Elasticsearch.  The index used is named &lt;code&gt;verrazzano-namespace-verrazzano-system&lt;/code&gt; because the VMI runs in the &lt;code&gt;verrazzano-system&lt;/code&gt; namespace.&lt;/p&gt;
&lt;p&gt;The same approach is used for both system and application logs.&lt;/p&gt;
&lt;h2 id=&#34;elasticsearch&#34;&gt;Elasticsearch&lt;/h2&gt;
&lt;p&gt;Verrazzano creates an Elasticsearch deployment as the store and search engine for the logs processed by Fluentd.  Records written by Fluentd can be queried using the Elasticsearch REST API.&lt;/p&gt;
&lt;p&gt;For example, you can use &lt;code&gt;curl&lt;/code&gt; to get all of the Elasticsearch indexes. First, you must get the password for the &lt;code&gt;verrazzano&lt;/code&gt; user and the host for the VMI Elasticsearch.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ PASS=$(kubectl get secret \
    --namespace verrazzano-system verrazzano \
    -o jsonpath={.data.password} | base64 \
    --decode; echo)
$ HOST=$(kubectl get ingress \
    -n verrazzano-system vmi-system-es-ingest \
    -o jsonpath={.spec.rules[0].host})

$ curl -ik \
   --user verrazzano:$PASS https://$HOST//_cat/indices
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To see all of the records for a specific index, do the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ INDEX=verrazzano-namespace-todo-list

$ curl -ik \
    --user verrazzano:$PASS https://$HOST/$INDEX/_doc/_search?q=message:*
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Verrazzano provides support for &lt;a href=&#34;../../docs/setup/install/profiles/&#34;&gt;Installation Profiles&lt;/a&gt;. The production profile (&lt;code&gt;prod&lt;/code&gt;), which is the default, provides a 3-node Elasticsearch and persistent storage for the Verrazzano Monitoring Instance (VMI). The development profile (&lt;code&gt;dev&lt;/code&gt;) provides a single node Elasticsearch and no persistent storage for the VMI. The &lt;code&gt;managed-cluster&lt;/code&gt; profile does not install Elasticsearch or Kibana in the local cluster; all logs are forwarded to the admin cluster&amp;rsquo;s Elasticsearch instance.&lt;/p&gt;
&lt;p&gt;If you want the logs sent to an external Elasticsearch, instead of the default VMI Elasticsearch, specify &lt;code&gt;elasticsearchURL&lt;/code&gt; and &lt;code&gt;elasticsearchSecret&lt;/code&gt; in the &lt;a href=&#34;../../docs/reference/api/verrazzano/verrazzano/#fluentd-component&#34;&gt;Fluentd&lt;/a&gt; Component configuration in your Verrazzano custom resource.&lt;/p&gt;
&lt;p&gt;The following is an example of a Verrazzano custom resource to send the logs to the Elasticsearch endpoint &lt;code&gt;https://external-es.default.172.18.0.231.nip.io&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: install.verrazzano.io/v1alpha1
kind: Verrazzano
metadata:
  name: default
spec:
  components:
    fluentd:
      elasticsearchURL: https://external-es.default.172.18.0.231.nip.io
      elasticsearchSecret: external-es-secret
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;kibana&#34;&gt;Kibana&lt;/h2&gt;
&lt;p&gt;Kibana is a visualization dashboard for the content indexed on an Elasticsearch cluster.  Verrazzano creates a Kibana deployment to provide a user interface for querying and visualizing the log data collected in Elasticsearch.&lt;/p&gt;
&lt;p&gt;To access the Kibana console, read &lt;a href=&#34;../../docs/operations/&#34;&gt;Access Verrazzano&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To see the records of an Elasticsearch index through Kibana, create an index pattern to filter for records under the desired index.&lt;/p&gt;
&lt;p&gt;For example, to see the log records of a WebLogic application deployed to the &lt;code&gt;todo-list&lt;/code&gt; namespace, create an index pattern of &lt;code&gt;verrazzano-namespace-todo-list&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../docs/images/kibana.png&#34; alt=&#34;Kibana&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Metrics</title>
      <link>/docs/monitoring/metrics/metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/monitoring/metrics/metrics/</guid>
      <description>
        
        
        &lt;p&gt;The Verrazzano metrics stack automates metrics aggregation and consists of Prometheus and Grafana components.
Metrics sources expose system and application metrics.
The Prometheus components retrieve and store the metrics and Grafana provides dashboards to
visualize them.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../docs/images/metrics.png&#34; alt=&#34;Metrics&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;metrics-sources&#34;&gt;Metrics sources&lt;/h2&gt;
&lt;p&gt;Metrics sources produce metrics and expose them to the Kubernetes Prometheus system using annotations in the pods.
The metrics annotations may differ slightly depending on the resource type.
The following is an example of the WebLogic Prometheus-related configuration specified in the &lt;code&gt;todo-list&lt;/code&gt; application pod:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ kubectl describe pod tododomain-adminserver -n todo-list&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Annotations:  prometheus.io/path: /wls-exporter/metrics
              prometheus.io/port: 7001
              prometheus.io/scrape: true
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For other resource types, such as Coherence or Helidon, the annotations would look similar to this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Annotations:  verrazzano.io/metricsEnabled: true
              verrazzano.io/metricsPath: /metrics
              verrazzano.io/metricsPort: 8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To look directly at the metrics that are being made available by the metric source, map the port and then access the path.&lt;/p&gt;
&lt;p&gt;For example, for the previous metric source:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Map the port being used to expose the metrics.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl port-forward tododomain-adminserver 7001:7001 -n todo-list
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Get the user name and password used to access the metrics source from the corresponding secret.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl get secret \
    --namespace todo-list tododomain-weblogic-credentials \
    -o jsonpath={.data.username} | base64 \
    --decode; echo
$ kubectl get secret \
    --namespace todo-list tododomain-weblogic-credentials \
    -o jsonpath={.data.password} | base64 \
    --decode; echo
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Access the metrics at the exported path, using the user name and password retrieved in the previous step.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ curl -u USERNAME:PASSWORD localhost:7001/wls-exporter/metrics
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;metrics-server&#34;&gt;Metrics server&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Single pod per cluster.&lt;/li&gt;
&lt;li&gt;Named &lt;code&gt;vmi-system-prometheus-*&lt;/code&gt; in &lt;code&gt;verrazzano-system&lt;/code&gt; namespace.&lt;/li&gt;
&lt;li&gt;Discovers exposed metrics source endpoints.&lt;/li&gt;
&lt;li&gt;Scrapes metrics from metrics sources.&lt;/li&gt;
&lt;li&gt;Responsible for exposing all metrics.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;grafana&#34;&gt;Grafana&lt;/h2&gt;
&lt;p&gt;Grafana provides visualization for your Prometheus metric data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Single pod per cluster.&lt;/li&gt;
&lt;li&gt;Named &lt;code&gt;vmi-system-grafana-*&lt;/code&gt; in &lt;code&gt;verrazzano-system&lt;/code&gt; namespace.&lt;/li&gt;
&lt;li&gt;Provides dashboards for metrics visualization.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To access Grafana:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Get the hostname from the Grafana ingress.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl get ingress vmi-system-grafana -n verrazzano-system

# Sample output
NAME                 CLASS    HOSTS                                              ADDRESS          PORTS     AGE
vmi-system-grafana   &amp;lt;none&amp;gt;   grafana.vmi.system.default.123.456.789.10.nip.io   123.456.789.10   80, 443   26h
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Get the password for the user &lt;code&gt;verrazzano&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl get secret \
    --namespace verrazzano-system verrazzano \
    -o jsonpath={.data.password} | base64 \
    --decode; echo
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Access Grafana in a browser using the previous hostname.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Log in using the &lt;code&gt;verrazzano&lt;/code&gt; user and the previous password.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;../../docs/images/grafana-initial-page.png&#34; alt=&#34;Grafana&#34;&gt;&lt;/p&gt;
&lt;p&gt;From here, you can select an existing dashboard or create a new dashboard.
To select an existing dashboard, use the drop-down list in the top left corner.
The initial value of this list is &lt;code&gt;Home&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To view host level metrics, select &lt;code&gt;Host Metrics&lt;/code&gt;. This will provide system metrics for all
of the nodes in your cluster.&lt;/p&gt;
&lt;p&gt;To view the application metrics for the &lt;code&gt;todo-list&lt;/code&gt; example application, select &lt;code&gt;WebLogic Server Dashboard&lt;/code&gt;
because the &lt;code&gt;todo-list&lt;/code&gt; application is a WebLogic application.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../docs/images/grafana-weblogic-dashboard.png&#34; alt=&#34;WebLogicDashboard&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
